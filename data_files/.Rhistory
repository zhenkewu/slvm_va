Y_mat[i] <- rnorm(1,mu_all[i],sqrt(sigma_squared))
}
V0_sqrt <- res_svd$u %*% diag(sqrt(res_svd$d)) %*%t(res_svd$v)
# to produce correlated measurements: (include the slopes for beta1)
Y_mat_correlated <- V0_sqrt %*% Y_mat
Y <- c(Y_mat_correlated) # stacking by column.
V <-  I_ms_by_ms%x%V0 # replaces the diagonals of the identity with V0: variance covariance matrix for all subjects. -> 120 * 120
geefit_geeM <- geem(Y ~ X, id = Id,
data = mydat, family = gaussian,
corstr = "fixed", corr.mat = V1)
mydat <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
colnames(mydat) <- c("Y", "X", "Id")
View(mydat)
geefit_geeM <- geem(Y ~ X, id = Id,
data = mydat, family = gaussian,
corstr = "fixed", corr.mat = V1)
resid <- Y - X %*% matrix(geefit_geeM$beta,ncol = 1)
resid_mat <- matrix(resid, nrow = n)
V0_empirical <- resid_mat %*% t(resid_mat)/(ms-1)
## start the replications for different values of rho
set.seed(20181001)
for(rep in 1:NREP){
Y_mat   <- matrix(0,nrow=n,ncol=ms)
res_svd <- svd(V0) #singular value decomposition.
for (i in 1:(ms*n)){
Y_mat[i] <- rnorm(1,mu_all[i],sqrt(sigma_squared))
}
V0_sqrt <- res_svd$u %*% diag(sqrt(res_svd$d)) %*%t(res_svd$v)
# to produce correlated measurements: (include the slopes for beta1)
Y_mat_correlated <- V0_sqrt %*% Y_mat
##create dataframe to estimate the betas via regression
regData <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
colnames(mydat) <- c("Y", "X", "Id")
Y <- c(Y_mat_correlated) # stacking by column.
V <-  I_ms_by_ms%x%V0 # replaces the diagonals of the identity with V0: variance covariance matrix for all subjects. -> 120 * 120
geefit_geeM1 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V1)
geefit_geeM2 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V2)
geefit_geeM3 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V3)
resid1 <- Y - X %*% matrix(geefit_geeM1$beta,ncol = 1)
resid2 <- Y - X %*% matrix(geefit_geeM2$beta,ncol = 1)
resid3 <- Y - X %*% matrix(geefit_geeM3$beta,ncol = 1)
resid_mat1 <- matrix(resid1, nrow = n)
resid_mat2 <- matrix(resid2, nrow = n)
resid_mat3 <- matrix(resid3, nrow = n)
V0_empirical1 <- resid_mat1 %*% t(resid_mat1)/(ms-1)
V0_empirical2 <- resid_mat1 %*% t(resid_mat2)/(ms-1)
V0_empirical3 <- resid_mat1 %*% t(resid_mat3)/(ms-1)
# V0_empirical <- var(t(Y_mat_correlated))
V_empirical1  <- I_ms_by_ms%x%V0_empirical1
V_empirical2  <- I_ms_by_ms%x%V0_empirical2
V_empirical3  <- I_ms_by_ms%x%V0_empirical3
wls_mat[1,rep] <- wls(Y,X,W1)[2]
wls_mat[2,rep] <- wls(Y,X,W2)[2]
wls_mat[3,rep] <- wls(Y,X,W3)[2]
wls_truth_vec[1,rep] <- var_wls_using_W_as_working(X,W1,V,sigma_squared)[2,2]
wls_truth_vec[2,rep] <- var_wls_using_W_as_working(X,W2,V,sigma_squared)[2,2]
wls_truth_vec[3,rep] <- var_wls_using_W_as_working(X,W3,V,sigma_squared)[2,2]
wls_sandwich_var_mat[1,rep] <- var_wls_using_W_as_working(X,W1,V_empirical1,sigma_squared)[2,2]
wls_sandwich_var_mat[2,rep] <- var_wls_using_W_as_working(X,W2,V_empirical2,sigma_squared)[2,2]
wls_sandwich_var_mat[3,rep] <- var_wls_using_W_as_working(X,W3,V_empirical3,sigma_squared)[2,2]
}
regData <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
View(regData)
## start the replications for different values of rho
set.seed(20181001)
for(rep in 1:NREP){
Y_mat   <- matrix(0,nrow=n,ncol=ms)
res_svd <- svd(V0) #singular value decomposition.
for (i in 1:(ms*n)){
Y_mat[i] <- rnorm(1,mu_all[i],sqrt(sigma_squared))
}
V0_sqrt <- res_svd$u %*% diag(sqrt(res_svd$d)) %*%t(res_svd$v)
# to produce correlated measurements: (include the slopes for beta1)
Y_mat_correlated <- V0_sqrt %*% Y_mat
##create dataframe to estimate the betas via regression
regData <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
colnames(regData) <- c("Y", "X", "Id")
Y <- c(Y_mat_correlated) # stacking by column.
V <-  I_ms_by_ms%x%V0 # replaces the diagonals of the identity with V0: variance covariance matrix for all subjects. -> 120 * 120
geefit_geeM1 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V1)
geefit_geeM2 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V2)
geefit_geeM3 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V3)
resid1 <- Y - X %*% matrix(geefit_geeM1$beta,ncol = 1)
resid2 <- Y - X %*% matrix(geefit_geeM2$beta,ncol = 1)
resid3 <- Y - X %*% matrix(geefit_geeM3$beta,ncol = 1)
resid_mat1 <- matrix(resid1, nrow = n)
resid_mat2 <- matrix(resid2, nrow = n)
resid_mat3 <- matrix(resid3, nrow = n)
V0_empirical1 <- resid_mat1 %*% t(resid_mat1)/(ms-1)
V0_empirical2 <- resid_mat1 %*% t(resid_mat2)/(ms-1)
V0_empirical3 <- resid_mat1 %*% t(resid_mat3)/(ms-1)
# V0_empirical <- var(t(Y_mat_correlated))
V_empirical1  <- I_ms_by_ms%x%V0_empirical1
V_empirical2  <- I_ms_by_ms%x%V0_empirical2
V_empirical3  <- I_ms_by_ms%x%V0_empirical3
wls_mat[1,rep] <- wls(Y,X,W1)[2]
wls_mat[2,rep] <- wls(Y,X,W2)[2]
wls_mat[3,rep] <- wls(Y,X,W3)[2]
wls_truth_vec[1,rep] <- var_wls_using_W_as_working(X,W1,V,sigma_squared)[2,2]
wls_truth_vec[2,rep] <- var_wls_using_W_as_working(X,W2,V,sigma_squared)[2,2]
wls_truth_vec[3,rep] <- var_wls_using_W_as_working(X,W3,V,sigma_squared)[2,2]
wls_sandwich_var_mat[1,rep] <- var_wls_using_W_as_working(X,W1,V_empirical1,sigma_squared)[2,2]
wls_sandwich_var_mat[2,rep] <- var_wls_using_W_as_working(X,W2,V_empirical2,sigma_squared)[2,2]
wls_sandwich_var_mat[3,rep] <- var_wls_using_W_as_working(X,W3,V_empirical3,sigma_squared)[2,2]
}
Y_mat   <- matrix(0,nrow=n,ncol=ms)
res_svd <- svd(V0) #singular value decomposition.
for (i in 1:(ms*n)){
Y_mat[i] <- rnorm(1,mu_all[i],sqrt(sigma_squared))
}
V0_sqrt <- res_svd$u %*% diag(sqrt(res_svd$d)) %*%t(res_svd$v)
# to produce correlated measurements: (include the slopes for beta1)
Y_mat_correlated <- V0_sqrt %*% Y_mat
##create dataframe to estimate the betas via regression
regData <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
colnames(regData) <- c("Y", "X", "Id")
Y <- c(Y_mat_correlated) # stacking by column.
V <-  I_ms_by_ms%x%V0 # replaces the diagonals of the identity with V0: variance covariance matrix for all subjects. -> 120 * 120
geefit_geeM1 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V1)
geefit_geeM2 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V2)
geefit_geeM3 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V3)
resid1 <- Y - X %*% matrix(geefit_geeM1$beta,ncol = 1)
resid2 <- Y - X %*% matrix(geefit_geeM2$beta,ncol = 1)
resid3 <- Y - X %*% matrix(geefit_geeM3$beta,ncol = 1)
resid_mat1 <- matrix(resid1, nrow = n)
resid_mat2 <- matrix(resid2, nrow = n)
resid_mat3 <- matrix(resid3, nrow = n)
V0_empirical1 <- resid_mat1 %*% t(resid_mat1)/(ms-1)
V0_empirical2 <- resid_mat1 %*% t(resid_mat2)/(ms-1)
V0_empirical3 <- resid_mat1 %*% t(resid_mat3)/(ms-1)
# V0_empirical <- var(t(Y_mat_correlated))
V_empirical1  <- I_ms_by_ms%x%V0_empirical1
V_empirical2  <- I_ms_by_ms%x%V0_empirical2
V_empirical3  <- I_ms_by_ms%x%V0_empirical3
wls_mat[1,rep] <- wls(Y,X,W1)[2]
wls_mat[2,rep] <- wls(Y,X,W2)[2]
wls_mat[3,rep] <- wls(Y,X,W3)[2]
wls_truth_vec[1,rep] <- var_wls_using_W_as_working(X,W1,V,sigma_squared)[2,2]
wls_truth_vec[2,rep] <- var_wls_using_W_as_working(X,W2,V,sigma_squared)[2,2]
wls_truth_vec[3,rep] <- var_wls_using_W_as_working(X,W3,V,sigma_squared)[2,2]
wls_sandwich_var_mat[1,rep] <- var_wls_using_W_as_working(X,W1,V_empirical1,sigma_squared)[2,2]
wls_sandwich_var_mat[2,rep] <- var_wls_using_W_as_working(X,W2,V_empirical2,sigma_squared)[2,2]
wls_sandwich_var_mat[3,rep] <- var_wls_using_W_as_working(X,W3,V_empirical3,sigma_squared)[2,2]
View(wls_sandwich_var_mat)
rho <- 0.5
rho12 <- rho # true correlation between Y_i1 and Y_i2.
rho13 <- rho^2 # true correlation between Y_i1 and Y_i3.
rho23 <- rho # true correlation between Y_i2 and Y_i3.
#true correlation matrix.
V0 <- matrix(c(1,rho12,rho13,
rho12,1,rho23,
rho13,rho23,1),nrow=3,ncol=3,byrow=TRUE)
# group 1's weight matrix:
V1 <- matrix(c(1,0.5, 0.8,
0.5,1,0.2,
0.8,0.2,1),nrow=3,ncol=3,byrow=TRUE)
V2 <- diag(rep(1,3))
V3 <-  matrix(c(1,rho12,rho13,
rho12,1,rho23,
rho13,rho23,1),nrow=3,ncol=3,byrow=TRUE)
NREP <- 500
ms <- 40 # number of subjects
## design matrix:
trt_sequence <- expand.grid(c(0,1), c(0,1), c(0,1))
X <- cbind(1, c(t(trt_sequence))) ## design matrix -> 8 * 3
for(i in 1:4){ # we want this to be 40*3 (40 subjects w/ three measurements) by 2 (intercept and slope)
X <- rbind(X, cbind(1, c(t(trt_sequence))))## design matrix
}
mu_all <- X %*% matrix(c(beta_0, beta_1), ncol=1) # holds the means
I_ms_by_ms <-  diag(rep(1,ms))
W1 <- solve(I_ms_by_ms%x%V1)
W2 <- solve(I_ms_by_ms%x%V2)
W3 <-solve(I_ms_by_ms%x%V3)
# for each data set, the following matrix stores sandwich variance estimators
# one per weigth matrix
wls_mat <- matrix(NA, nrow=3, ncol=NREP)
wls_truth_vec  <- matrix(NA,nrow=3,ncol=NREP)
wls_sandwich_var_mat   <- matrix(NA,nrow=3,ncol=NREP)
rownames(wls_sandwich_var_mat) <- c("group1","group2","group3")
## start the replications for different values of rho
set.seed(20181001)
for(rep in 1:NREP){
Y_mat   <- matrix(0,nrow=n,ncol=ms)
res_svd <- svd(V0) #singular value decomposition.
for (i in 1:(ms*n)){
Y_mat[i] <- rnorm(1,mu_all[i],sqrt(sigma_squared))
}
V0_sqrt <- res_svd$u %*% diag(sqrt(res_svd$d)) %*%t(res_svd$v)
# to produce correlated measurements: (include the slopes for beta1)
Y_mat_correlated <- V0_sqrt %*% Y_mat
##create dataframe to estimate the betas via regression
regData <- data.frame(cbind(Y, X[, 2], rep(1:ms, each = n)))
colnames(regData) <- c("Y", "X", "Id")
Y <- c(Y_mat_correlated) # stacking by column.
V <-  I_ms_by_ms%x%V0 # replaces the diagonals of the identity with V0: variance covariance matrix for all subjects. -> 120 * 120
geefit_geeM1 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V1)
geefit_geeM2 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V2)
geefit_geeM3 <- geem(Y ~ X, id = Id, data = regData,
family = gaussian, corstr = "fixed",
corr.mat = V3)
resid1 <- Y - X %*% matrix(geefit_geeM1$beta,ncol = 1)
resid2 <- Y - X %*% matrix(geefit_geeM2$beta,ncol = 1)
resid3 <- Y - X %*% matrix(geefit_geeM3$beta,ncol = 1)
resid_mat1 <- matrix(resid1, nrow = n)
resid_mat2 <- matrix(resid2, nrow = n)
resid_mat3 <- matrix(resid3, nrow = n)
V0_empirical1 <- resid_mat1 %*% t(resid_mat1)/(ms-1)
V0_empirical2 <- resid_mat1 %*% t(resid_mat2)/(ms-1)
V0_empirical3 <- resid_mat1 %*% t(resid_mat3)/(ms-1)
# V0_empirical <- var(t(Y_mat_correlated))
V_empirical1  <- I_ms_by_ms%x%V0_empirical1
V_empirical2  <- I_ms_by_ms%x%V0_empirical2
V_empirical3  <- I_ms_by_ms%x%V0_empirical3
wls_mat[1,rep] <- wls(Y,X,W1)[2]
wls_mat[2,rep] <- wls(Y,X,W2)[2]
wls_mat[3,rep] <- wls(Y,X,W3)[2]
wls_truth_vec[1,rep] <- var_wls_using_W_as_working(X,W1,V,sigma_squared)[2,2]
wls_truth_vec[2,rep] <- var_wls_using_W_as_working(X,W2,V,sigma_squared)[2,2]
wls_truth_vec[3,rep] <- var_wls_using_W_as_working(X,W3,V,sigma_squared)[2,2]
wls_sandwich_var_mat[1,rep] <- var_wls_using_W_as_working(X,W1,V_empirical1,sigma_squared)[2,2]
wls_sandwich_var_mat[2,rep] <- var_wls_using_W_as_working(X,W2,V_empirical2,sigma_squared)[2,2]
wls_sandwich_var_mat[3,rep] <- var_wls_using_W_as_working(X,W3,V_empirical3,sigma_squared)[2,2]
}
apply(wls_mat,1,var)
apply(wls_truth_vec,1,mean)
apply(wls_sandwich_var_mat,1,mean)
plot(rho_vec, rel_efficiency,
type = "o", lwd = 2, col = "red", xlab = expression(rho),
main="Relative Efficiency of WLS vs. OLS")
library(foreign)
cholesterol_data <- data.table(read.dta("~/Library/Mobile Documents/com~apple~CloudDocs/School/Fall 2019/Biostat 653/hw2/cholesterol.dta"))
summaryStats <-cholesterol_data[,list(y1_mean=mean(na.omit(y1)),
y1_sd = sd(na.omit(y1)),
y1_var = var(na.omit(y1)),
y2_mean=mean(na.omit(y2)),
y2_sd = sd(na.omit(y2)),
y2_var = var(na.omit(y2)),
y3_mean=mean(na.omit(y3)),
y3_sd = sd(na.omit(y3)),
y3_var = var(na.omit(y3)),
y4_mean=mean(na.omit(y4)),
y4_sd = sd(na.omit(y4)),
y4_var = var(na.omit(y4)),
y5_mean=mean(na.omit(y5)),
y5_sd = sd(na.omit(y5)),
y5_var = var(na.omit(y5))), by=c("group")]
summaryStats
summaryStats$group <- as.factor(summaryStats$group)
summaryStats_long <- melt(summaryStats, id.vars = "group", variable.name="time", value.name="mean_cholesterol")
## get the means
meanData <- summaryStats_long[time%in%c("y1_mean", "y2_mean", "y3_mean", "y4_mean", "y5_mean")]
ggplot(meanData)+
geom_line(aes(x=time, y=mean_cholesterol, group=group, colour=group)) +
ylab("Mean Cholesterol")+
xlab("Time") +
labs(title="Mean Serum Cholesterol over Time")
rm(list=ls())
library(data.table)
library(ggplot2)
library(plyr)
library(dplyr)
library(readxl)
library(foreign)
library(nnet)
library(grDevices)
library(gplots)
library(plotly)
library(broom)
##----------------------------
### load the VA datasets ###
##----------------------------
setwd("/Users/irena/repos/slvm_va/data_files/")
dataFreeze <-  data.table(read.csv("data_freeze_10062019.csv"))
dataDict <- data.table(read_excel("data_dictionary.xlsx"))
dataFreeze$sex <- ifelse(dataFreeze$g1_05==1, "Female", "Male")
regData <- dataFreeze[,  c("gs_text34",#main CoD
"g4_08", #separate room for cooking
"g5_06a", # education level
#"g5_06b",  # of years of education
"g1_06y", "g1_06m", "g1_06d", # day, month, year of death
"site", "sex"), with=FALSE]
## check how many missing values:
sum(is.na(regData))
## 66 missing values - for now, just drop:
regData_noNA <- na.omit(regData)
# regData_noNA$cod_dates <-paste(regData_noNA$g1_06y, regData_noNA$g1_06m,
#                                regData_noNA$g1_06d,sep="-")
##
### Since there are a relatively high # of unique CoD, we will create a meta-category column to group similar CoD
## generally following what the IHME website has:
create_meta_adult_cod <- function(x){
category = x
if(grepl(paste(c("Bite of Venomous Animal", "Violent Death", "Road Traffic",
"Poisonings", "Drowning", "Homicide","Falls", "Fires", "Other Injuries"), collapse = "|"),x)){
category = "External"
} else if(grepl(paste(c("Diarrhea/Dysentery", "Encephalitis", "Meningitis", "Measles",
"Hemorrhagic fever", "Other Infectious Diseases"), collapse = "|"), x)){
category = "Infectious"
} else if(grepl(paste(c("Malaria","AIDS", "TB"), collapse = "|"), x)){
category = "Global Epidemic"
} else if(grepl(paste(c("Pneumonia", "Asthma","COPD"), collapse = "|"), x)){
category = "Respiratory"
} else if(grepl(paste(c("Renal Failure"), collapse = "|"),x)){
category = "Renal Failure"
} else if(grepl(paste(c("Acute Myocardial Infarction", "Stroke","Other Cardiovascular Diseases"), collapse = "|"),x)){
category = "CVD"
} else if (grepl(paste(c("Stomach Cancer","Breast Cancer", "Esophageal Cancer", "Prostate Cancer",
"Colorectal Cancer", "Cervical Cancer", "Lung Cancer", "Leukemia/Lymphomas"), collapse="|"),x)){
category = "Cancer"
} else if (grepl(c("Suicide"),x)){
category = "Suicide"
} else if (grepl(c("Maternal"),x)){
category = "Maternal"
} else if (grepl(paste(c("Diabetes", "Epilepsy","Cirrhosis","Other Non-communicable Diseases"),
collapse="|"),x)){
category = "Noncommunicable \n Diseases"
}
return(category)
}
regData_noNA$meta_cod <- mapply(create_meta_adult_cod, regData_noNA$gs_text34)
## remove maternal CoD - since there will be zero counts for males
regData_noNA <- regData_noNA[!meta_cod=="Maternal"]
## -------------------------
## Check that there are no empty cells for the multinom regression
## ------------------------
## highest counts of month of death are November
regData_noNA$death <- 1
regData_noNA[,list(death_count=sum(death)), by=c("g1_06m")]
# relevel the month variable so November is the reference category:
regData_noNA$g1_06m <- relevel(regData_noNA$g1_06m, " November")
# regData_noNA$month <- copy(regData_noNA$g1_06m)
# regData_noNA[month=="April", month:="May"]
## for level of education: make "Primary School" the reference category:
regData_noNA[,list(death_count=sum(death)), by=c("g5_06a")]
regData_noNA$g5_06a <- relevel(regData_noNA$g5_06a,"Primary School")
## for # of years in school, make 0 the reference category: 10/15 - removed for now because it has many categories
# regData_noNA[,list(death_count=sum(death)), by=c("g5_06b")]
# regData_noNA$g5_06b <- relevel(regData_noNA$g5_06b, "0")
### make "Yes" the reference for "do you have a separate room for cooking"
regData_noNA[,list(death_count=sum(death)), by=c("g4_08")]
regData_noNA$g4_08 <- relevel(regData_noNA$g4_08, "Yes")
### make CVD the reference category for the broader/coarser causes of death
regData_noNA[,list(death_count=sum(death)), by=c("meta_cod")]
regData_noNA$meta_cod <- as.factor(regData_noNA$meta_cod)
regData_noNA$meta_cod <- relevel(regData_noNA$meta_cod, "CVD")
### make Mexico the reference category for the broader/coarser causes of death
regData_noNA[,list(death_count=sum(death)), by=c("site")]
regData_noNA$site <- relevel(regData_noNA$site,"Mexico")
### make male the reference for sex variable:
regData_noNA[,list(death_count=sum(death)), by=c("sex")]
regData_noNA$sex <- as.factor(regData_noNA$sex)
regData_noNA$sex <- relevel(regData_noNA$sex, "Male")
##### -------------------------
## Multinomial regression
##### -------------------------
multinom_explore <- multinom(formula =meta_cod~ site + sex +g4_08 + g5_06a + g1_06m,
data = regData_noNA,maxit=1000,
family="multinomial",MaxNWts =1000, reltol=1.0e-12)
multinom_results <- coef(multinom_explore)
multinom_tidy <- tidy(multinom_explore)
multinom_std <- multinom_tidy$std.error
plot(density(abs(colSums(multinom_results))))
heatmap.2(multinom_results,col=blueyelred,margins = c(10, 8))
xform <- list(categoryorder = "array",
categoryarray = c("(Intercept)",
"sexFemale",
"g4_08No",
"siteAP",
"siteUP",
"siteBohol",
"siteDar",
"sitePemba",
"g5_06aNo Schooling",
"g5_06aHigh School",
"g5_06aCollege or Higher",
"g5_06aUnknown",
"g1_06mJanuary",
"g1_06mFebruary",
"g1_06mMarch",
"g1_06mApril",
"g1_06mMay",
"g1_06mJune",
"g1_06mJuly",
"g1_06mAugust",
"g1_06mSeptember",
"g1_06mOctober",
"g1_06mDecember",
"g1_06mDon't Know"))
plot_ly(z=round(log(multinom_tidy$estimate),3),
type="heatmap",y=multinom_tidy$y.level,x=multinom_tidy$term,
text=paste(
"std. error:", round(multinom_tidy$std.error, 3)
)) %>%
layout(xaxis = xform, title="Regression Coefficients")
plot_ly(z=round((multinom_tidy$std.error),3),
type="heatmap",y=multinom_tidy$y.level,x=multinom_tidy$term) %>%
layout(xaxis = xform, title="Standard Errors")
###---------------------
### DROP PEMBA
###---------------------
regData_noPemba <- regData_noNA[site!="Pemba"]
# regData_noPemba <- regData_noPemba[g1_06m!="April"]
regData_noPemba$site <- as.character(regData_noPemba$site)
regData_noPemba$site <- factor(regData_noPemba$site, levels=c("Mexico", "AP", "UP", "Bohol", "Dar"))
multinom_noPemba <- multinom(formula =meta_cod~ site + sex +g4_08 + g5_06a + g1_06m,
data = regData_noPemba,maxit=1000,
family="multinomial",MaxNWts =1000, reltol=1.0e-12)
tidy_multinom_noPemba <- tidy(multinom_noPemba)
#multinom_tidy$log_estimate <- log(multinom_tidy$estimate)
xform_noPemba <- list(categoryorder = "array",
categoryarray = c("(Intercept)",
"sexFemale",
"g4_08No",
"siteAP",
"siteUP",
"siteBohol",
"siteDar",
"g5_06aNo Schooling",
"g5_06aHigh School",
"g5_06aCollege or Higher",
"g5_06aUnknown",
"g1_06mJanuary",
"g1_06mFebruary",
"g1_06mMarch",
"g1_06mApril",
"g1_06mMay",
"g1_06mJune",
"g1_06mJuly",
"g1_06mAugust",
"g1_06mSeptember",
"g1_06mOctober",
"g1_06mDecember",
"g1_06mDon't Know"))
plot_ly(z=round(log(tidy_multinom_noPemba$estimate),3),
type="heatmap",y=tidy_multinom_noPemba$y.level,x=tidy_multinom_noPemba$term,
text=paste(
"std. error:", round(tidy_multinom_noPemba$std.error, 3)
)) %>%
layout(xaxis = xform_noPemba, title="Regression Coefficients (after excluding Pemba)")
plot_ly(z=round((tidy_multinom_noPemba$std.error),3),
type="heatmap",y=tidy_multinom_noPemba$y.level,x=tidy_multinom_noPemba$term) %>%
layout(xaxis = xform_noPemba, title="Standard Errors (after excluding Pemba)")
###---------------------
### DROP "Don't Know" for month of death (there are only six observations)
###---------------------
regData_noPemba <- regData_noPemba[!g1_06m%in%c("Don't Know")]
# regData_noPemba <- regData_noPemba[g1_06m!="April"]
regData_noPemba$g1_06m <- as.character(regData_noPemba$g1_06m)
regData_noPemba$g1_06m <- factor(regData_noPemba$g1_06m)
regData_noPemba$g1_06m <- relevel(regData_noPemba$g1_06m," November")
multinom_noPemba2 <- multinom(formula =meta_cod~ site + sex +g4_08 + g5_06a + g1_06m,
data = regData_noPemba,maxit=1000,
family="multinomial",MaxNWts =1000, reltol=1.0e-12)
tidy_multinom_noPemba2 <- tidy(multinom_noPemba2)
#multinom_tidy$log_estimate <- log(multinom_tidy$estimate)
xform_noPemba2 <- list(categoryorder = "array",
categoryarray = c("(Intercept)",
"sexFemale",
"g4_08No",
"siteAP",
"siteUP",
"siteBohol",
"siteDar",
"g5_06aNo Schooling",
"g5_06aHigh School",
"g5_06aCollege or Higher",
"g5_06aUnknown",
"g1_06mJanuary",
"g1_06mFebruary",
"g1_06mMarch",
"g1_06mApril",
"g1_06mMay",
"g1_06mJune",
"g1_06mJuly",
"g1_06mAugust",
"g1_06mSeptember",
"g1_06mOctober",
"g1_06mDecember"))
plot_ly(z=round(log(tidy_multinom_noPemba2$estimate),3),
type="heatmap",y=tidy_multinom_noPemba2$y.level,x=tidy_multinom_noPemba2$term,
text=paste(
"std. error:", round(tidy_multinom_noPemba2$std.error, 3)
)) %>%
layout(xaxis = xform_noPemba2, title="Regression after removing Pemba and Unknown Month of Death")
plot_ly(z=round(log(tidy_multinom_noPemba2$std.error),3),
type="heatmap",y=tidy_multinom_noPemba2$y.level,x=tidy_multinom_noPemba2$term,
text=paste(
"std. error:", round(tidy_multinom_noPemba2$std.error, 3)
)) %>%
layout(xaxis = xform_noPemba2, title="Std. Errors after removing Pemba and Unknown Month of Death")
